nextflow.enable.dsl = 2

params {
    input = null
    outdir = 'results'
    genome = null
    seq_center = null
    enable_conda = false
    publish_dir_mode = "copy"

    cutadapt {
        adapters = '/opt2/TruSeq_and_nextera_adapters.consolidated.fa'
        minlen = 20
        leadingquality = 10
        trailingquality = 10
    }
    fastq_screen {
        conf = "${baseDir}/assets/fastq_screen.conf"
        db_dir = '/data/CCBR_Pipeliner/db/PipeDB/lib/fastq_screen_db/'
    }
    align {
        index_dir = "/data/CCBR_Pipeliner/db/PipeDB/Indices/${params.genome}_basic/indexes/"
        blacklist = "${params.genome}.blacklist"
        blacklist_files = "${params.align.index_dir}${params.align.blacklist}*"
        reference_files = "${params.align.index_dir}${params.genome}*"
        min_quality = 6                     // to get a min quality of 5, set this to 6
        effective_genome_size = 2700000000  // source: https://github.com/CCBR/Pipeliner/blob/86c6ccaa3d58381a0ffd696bbf9c047e4f991f9e/hg38.json#L349
        chrom_sizes = "${params.align.index_dir}${params.genome}.fa.sizes"       // source: https://github.com/CCBR/Pipeliner/blob/86c6ccaa3d58381a0ffd696bbf9c047e4f991f9e/hg38.json#L359
    }
    deeptools {
        bin_size = 25
        smooth_length = 75
        normalize_using = "RPGC"
        excluded_chroms = "chrM chrX chrY"
    }
    gene_info = "/data/CCBR_Pipeliner/db/PipeDB/Indices/${params.genome}_basic/geneinfo.bed"
    multiqc_config = "${baseDir}/assets/multiqc_config.yaml"
    min_fragment_length = 200 // https://github.com/CCBR/Pipeliner/blob/86c6ccaa3d58381a0ffd696bbf9c047e4f991f9e/Rules/InitialChIPseqQC.snakefile#L539
}

includeConfig 'conf/base.config'

profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    docker {
        docker.enabled = true
        // Avoid this error:
        //   WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
        // Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
        // once this is established and works well, nextflow might implement this behavior as new default.
        docker.runOptions = '-u \$(id -u):\$(id -g)'
    }
    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
        singularity.cacheDir = "/data/$USER/.singularity" // TODO this may be a different default on other (non biowulf) platforms
        envWhitelist='https_proxy,http_proxy,ftp_proxy,DISPLAY,SLURM_JOBID,SINGULARITY_BINDPATH'
    }
    biowulf {
        includeConfig "conf/biowulf.config"
    }
    slurmint {
        includeConfig "conf/slurmint.config"
    }
    test {
        includeConfig "conf/test.config"
    }
    test_mm10 {
        includeConfig "conf/test_mm10.config"
    }
    ci_stub {
        includeConfig "conf/ci_stub.config"
    }
}

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.
env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format('yyyy-MM-dd_HH-mm-ss')
dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/pipeline_dag_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/execution_report_${trace_timestamp}.html"
}

includeConfig 'conf/modules.config'

manifest {
    name = "CCBR/CHAMPAGNE"
    author = "CCR Collaborative Bioinformatics Resource"
    homePage = "https://github.com/CCBR/CHAMPAGNE"
    description = "CHromAtin iMmuno PrecipitAtion sequencinG aNalysis pipEline"
    mainScript = "main.nf"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
