params {
    input = null
    outputDir = "${outputDir}"
    tracedir = "${outputDir}/pipeline_info"
    genome = null // must be listed in conf/genomes.config
    seq_center = null
    read_length = null

    // comma separated list of column names in the input samplesheet for contrasts
    // e.g. 'condition' or 'condition,timepoint' if these are columns in your samplesheet.
    contrasts = null

    // spike-in normalization options
    // genome must be listed in conf/genomes.config
    spike_genome = null
    spike_norm_method = 'guenther' // guenther, delorenzi
    spike_deeptools_bin_size = 5000 // used in deepTools multiBamSummary for Delorenzi method
    spike_deeptools_min_map_quality = 30 // used in deepTools multiBamSummary for Delorenzi method

    // custom genome options
    genome_fasta = null
    genes_gtf   = null
    blacklist = null
    rename_contigs = null

    // Boilerplate options
    publish_dir_mode = 'link'

    // Max resource options
    max_memory = '224 GB'
    max_cpus = 32
    max_time = '72 h'

    // CCBR shared resource paths
    index_dir = null
    fastq_screen_conf = null
    fastq_screen_db_dir = null

    // Pipeline options
    align_min_quality = 6 // to get a min quality of 5, set this to 6
    deeptools_bin_size = 25
    deeptools_smooth_length = 75
    deeptools_normalize_using = "RPGC" // set this to "None" if using a spike-in control
    deeptools_excluded_chroms = "chrM chrX chrY"

    multiqc_config = "${projectDir}/assets/multiqc_config.yaml"
    multiqc_logo = "${projectDir}/assets/ccbr_logo.png"

    min_fragment_length = 200 // https://github.com/CCBR/Pipeliner/blob/86c6ccaa3d58381a0ffd696bbf9c047e4f991f9e/Rules/InitialChIPseqQC.snakefile#L539

    gem_read_dists = "${projectDir}/assets/gem/Read_Distribution_default.txt" // source https://groups.csail.mit.edu/cgs/gem/download/Read_Distribution_default.txt
    gem_fold = 3
    gem_k_min = 6
    gem_k_max = 13
    macs_narrow_q = 0.01
    macs_broad_q = 0.01
    macs_broad_cutoff = 0.01
    sicer_species = "${params.genome}" // supported species https://github.com/zanglab/SICER2/blob/master/sicer/lib/GenomeData.py

    homer_de_novo = true
    homer_jaspar_db = "${projectDir}/assets/JASPAR2022_CORE_vertebrates_non-redundant_pfms_jaspar.txt" // source https://jaspar.genereg.net/download/data/2022/CORE/JASPAR2022_CORE_vertebrates_non-redundant_pfms_jaspar.txt

    diffbind_report = "${projectDir}/assets/diffbind_report.Rmd"

    // some steps can be turned on/off for debugging purposes
    run_qc = true
    run_deeptools = true
    run_normalize_input = true
    run_call_peaks = true
    run_gem = true
    run_sicer = true
    run_macs_broad = true
    run_macs_narrow = true
    run_normalize_peaks = false
    run_chipseeker = false
    run_homer = true
    run_meme = true
    run_consensus_union = true
    run_consensus_corces = true

}


includeConfig 'conf/base.config'

profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    docker {
        docker.enabled = true
        // Avoid this error:
        //   WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. Memory limited without swap.
        // Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351
        // once this is established and works well, nextflow might implement this behavior as new default.
        docker.runOptions = '-u \$(id -u):\$(id -g)'
    }
    singularity {
        singularity.enabled = true
        singularity.autoMounts = true
        singularity.cacheDir = null // overridden by profiles: biowulf, frce, & slurmint
        envWhitelist='https_proxy,http_proxy,ftp_proxy,DISPLAY,SLURM_JOBID,SINGULARITY_BINDPATH'
    }
    biowulf {
        includeConfig "conf/biowulf.config"
    }
    slurm {
        includeConfig "conf/slurm.config"
    }
    interactive {
        includeConfig "conf/interactive.config"
    }
    test {
        includeConfig "conf/test.config"
    }
    test_mm10 {
        includeConfig "conf/test_mm10.config"
    }
    full_mm10 {
        includeConfig "conf/full_mm10.config"
    }
    test_human {
        includeConfig 'conf/test_human.config'
    }
    test_spikein {
        includeConfig 'conf/test_spikein.config'
    }
}

includeConfig 'conf/genomes.config'
includeConfig 'conf/containers.config'
includeConfig 'conf/modules.config'

// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.
env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format('yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.png"
}



plugins {
  id 'nf-schema@2.2.1'
  id 'nf-prov@1.4.0'
}
validation {
    help {
        enabled = true
    }
}
prov {
    enabled = true
    formats {
        bco {
            file = "${params.tracedir}/bco.json"
            overwrite = true
        }
        dag {
            file = "${params.tracedir}/dag.html"
            overwrite = true
        }
    }
}

String pipeline_version = new File("${projectDir}/VERSION").text

manifest {
    name = "CCBR/CHAMPAGNE"
    author = "CCR Collaborative Bioinformatics Resource"
    homePage = "https://github.com/CCBR/CHAMPAGNE"
    description = "CHromAtin iMmuno PrecipitAtion sequencinG aNalysis pipEline"
    mainScript = "main.nf"
    defaultBranch = "main"
    version = "${pipeline_version}"
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

workflow.output.mode = params.publish_dir_mode
